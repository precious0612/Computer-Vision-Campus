{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR-100数据集图像的均值和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR100_TRAIN_MEAN = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n",
    "CIFAR100_TRAIN_STD = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练数据使用随机切割、水平翻转、随机旋转的数据增强，并进行归一化处理\n",
    "#### 验证数据仅使用归一化，不进行数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Max\n",
      "\n",
      "systemMemory: 96.00 GB\n",
      "maxCacheSize: 36.00 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 00:24:04.338030: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-22 00:24:04.338728: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    " 'train': keras.Sequential([\n",
    " layers.experimental.preprocessing.RandomCrop(32, 32),\n",
    " layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    " layers.experimental.preprocessing.RandomRotation(0.15),\n",
    " layers.experimental.preprocessing.Rescaling(1./255),\n",
    " layers.experimental.preprocessing.Normalization(mean=CIFAR100_TRAIN_MEAN, variance=CIFAR100_TRAIN_STD)\n",
    " ]),\n",
    " 'val': keras.Sequential([\n",
    " layers.experimental.preprocessing.Rescaling(1./255),\n",
    " layers.experimental.preprocessing.Normalization(mean=CIFAR100_TRAIN_MEAN, variance=CIFAR100_TRAIN_STD)\n",
    " ]),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 搭建训练和验证数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169001437/169001437 [==============================] - 29s 0us/step\n"
     ]
    }
   ],
   "source": [
    "Mode = {'train':True, 'val':False}\n",
    "\n",
    "image_datasets = {x: tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")[Mode[x]]\n",
    " for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {'train': tf.data.Dataset.from_tensor_slices(image_datasets['train']).batch(128).shuffle(128), 'val': tf.data.Dataset.from_tensor_slices(image_datasets['val']).batch(128)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取数据集大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x][0]) for x in ['train', 'val']}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取数据集的类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.unique(image_datasets['train'][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像展示函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        plt.pause(0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从数据集中取出一组样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(dataloaders['train']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将一组样本拼成一幅图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tf.concat([inputs[i] for i in range(8)], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在屏幕中展示图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/gg60t0gj07db4xt45161nvz80000gn/T/ipykernel_93759/92367330.py:2: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  imshow(out, title=[class_names[x] for x in classes[:8]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ion()\n",
    "imshow(out, title=[class_names[x] for x in classes[:8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'cifar-100-python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m train_paths \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m))]\n\u001b[1;32m     15\u001b[0m val_paths \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m, f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m))]\n\u001b[0;32m---> 17\u001b[0m train_labels \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(f\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m))]\n\u001b[1;32m     18\u001b[0m val_labels \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(f\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m))]\n\u001b[1;32m     20\u001b[0m train_ds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices((train_paths, train_labels))\n",
      "Cell \u001b[0;32mIn[36], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m train_paths \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m))]\n\u001b[1;32m     15\u001b[0m val_paths \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m, f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m))]\n\u001b[0;32m---> 17\u001b[0m train_labels \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39;49m(f\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39;49m]) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m))]\n\u001b[1;32m     18\u001b[0m val_labels \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(f\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mcifar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m))]\n\u001b[1;32m     20\u001b[0m train_ds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices((train_paths, train_labels))\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'cifar-100-python'"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 实例化 ResNet-18 模型\n",
    "model = keras.applications.ResNet18(\n",
    "    include_top=False, # 是否包含最后的全连接层\n",
    "    weights=\"imagenet\", # 使用 ImageNet 预训练的权重\n",
    "    input_shape=(32, 32, 3), # 输入图像的形状\n",
    "    pooling=None, # 特征提取时的池化方式\n",
    ")\n",
    "\n",
    "# 添加自定义的层\n",
    "x = layers.GlobalAveragePooling2D()(model.output)\n",
    "output = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = keras.Model(model.inputs, output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=2e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model.fit(image_datasets['train'], epochs=25, validation_data=image_datasets['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
